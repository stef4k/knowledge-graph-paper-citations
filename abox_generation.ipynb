{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a5d82a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph, Namespace, URIRef #import already in RDFlib integrated namespaces \n",
    "import pandas as pd #for handling csv and csv contents       \n",
    "from owlrl import DeductiveClosure, RDFS_Semantics\n",
    "import hashlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f339eafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total triples: 80\n"
     ]
    }
   ],
   "source": [
    "g = Graph()\n",
    "g.parse(\"output_files/ontology.ttl\", format=\"turtle\")\n",
    "DBO = Namespace(\"http://dbpedia.org/ontology/\")\n",
    "DBR = Namespace(\"http://dbpedia.org/resource/\")\n",
    "\n",
    "\n",
    "g.bind(\"dbo\", DBO)\n",
    "g.bind(\"dbr\", DBR)\n",
    "\n",
    "print(f\"Total triples: {len(g)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "820a44bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def consistent_hash(value):\n",
    "    return int(hashlib.sha256(str(value).encode()).hexdigest(), 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "932a5d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ConferenceEdition -is_edition_of_conf-> Conference\n",
    "# WorkshopEdition -is_edition_of_workshop-> Workshop\n",
    "path_ed='data/is_edition_of_relationships.csv'\n",
    "path2='data/conferences.csv'\n",
    "df_ed=pd.read_csv(path_ed,sep=\",\")\n",
    "df2=pd.read_csv(path2,sep=\",\")\n",
    "df= pd.merge(df_ed, df2, on='confID')\n",
    "for index, row in df.iterrows():\n",
    "    if row['type'] == 'conference':\n",
    "        g.add((URIRef(DBR+str(row['editionID'])), DBO.is_edition_of_conf, URIRef(DBR+str(row['confID']))))\n",
    "    elif row['type'] == 'workshop':\n",
    "        g.add((URIRef(DBR+str(row['editionID'])), DBO.is_edition_of_workshop, URIRef(DBR+str(row['confID']))))\n",
    "    else:\n",
    "        print(\"Unknown type:\", row['type'])\n",
    "\n",
    "# ConferenceChair -organizes_conference-> Conference\n",
    "# ConferenceChair -organizes_workshop-> Workshop\n",
    "# JournalEditor -edits-> Journal\n",
    "path='data/coordinators.csv'\n",
    "df=pd.read_csv(path,sep=\",\")\n",
    "path1='data/journals.csv'\n",
    "df1=pd.read_csv(path1,sep=\",\")\n",
    "dict = {}\n",
    "for index, row in df.iterrows():\n",
    "    if index < len(df2):\n",
    "        if df2.loc[index]['type']== 'conference':\n",
    "            g.add((URIRef(DBR+str(row['id'])), DBO.organizes_conference, URIRef(DBR+str(df2.loc[index]['confID']))))\n",
    "            dict[str(df2.loc[index]['confID'])] = str(row['id'])\n",
    "        else:\n",
    "            g.add((URIRef(DBR+str(row['id'])), DBO.organizes_workshop, URIRef(DBR+str(df2.loc[index]['confID']))))\n",
    "            dict[str(df2.loc[index]['confID'])] = str(row['id'])\n",
    "    else:\n",
    "        g.add((URIRef(DBR+str(row['id'])), DBO.edits, URIRef(DBR+str(consistent_hash(df1.loc[index-len(df2)]['journalID'])))))\n",
    "        dict[str(consistent_hash(df1.loc[index-len(df2)]['journalID']))] = str(row['id'])\n",
    "\n",
    "\n",
    "# Paper -published_in-> JournalVolume\n",
    "path_pub='data/published_in_relationships.csv'\n",
    "df_pub=pd.read_csv(path_pub,sep=\",\")\n",
    "for index, row in df_pub.iterrows():\n",
    "    g.add((URIRef(DBR+str(row['paperID'])), DBO.published_in, URIRef(DBR+str(row['volumeID']).replace(\" \", \"\"))))\n",
    "\n",
    "\n",
    "# JournalVolume -is_volume_of-> Journal\n",
    "path_vol='data/is_volume_of_relationships.csv'\n",
    "df_vol=pd.read_csv(path_vol,sep=\",\")\n",
    "for index, row in df_vol.iterrows():\n",
    "    g.add((URIRef(DBR+str(row['volumeID']).replace(\" \", \"\")), DBO.is_volume_of, URIRef(DBR+str(consistent_hash(row['journalID'])))))\n",
    "\n",
    "\n",
    "# Paper -presentedAt-> EventEdition\n",
    "path_pres='data/presented_in_relationships.csv'\n",
    "df_pres=pd.read_csv(path_pres,sep=\",\")\n",
    "for index, row in df_pres.iterrows():\n",
    "    g.add((URIRef(DBR+str(row['paperID'])), DBO.presentedAt, URIRef(DBR+str(row['editionID']))))\n",
    "\n",
    "# Review -review_written_by-> Reviewer\n",
    "# Review -corresponds_to_paper-> Paper\n",
    "#I WONDER IF THIS LINK COULD BE INFERRED BY REASONING\n",
    "#Review -is_assigned_by-> Coordinator   \n",
    "path=\"data/evolved_reviews_relationships.csv\"\n",
    "df=pd.read_csv(path,sep=\",\")\n",
    "df_merged1 = pd.merge(df_pub, df_vol, on='volumeID')\n",
    "df_merged2 = pd.merge(df_pres, df_ed, on='editionID')\n",
    "\n",
    "union_df = pd.concat([df_merged1, df_merged2], ignore_index=True)\n",
    "df1= pd.merge(df, union_df, on='paperID')\n",
    "df1['hashed_journalID'] =df1['journalID'].apply(consistent_hash)\n",
    "df1['combined'] = df1['confID'].combine_first(df1['hashed_journalID'])\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "     coordinator=str(dict[str(df1[df1['content'] == row['content']]['combined'].values[0])])\n",
    "     g.add((URIRef(DBR+str(consistent_hash(row['content']))), DBO.review_written_by, URIRef(DBR+str(row['authorID']))))\n",
    "     g.add((URIRef(DBR+str(consistent_hash(row['content']))), DBO.corresponds_to_paper, URIRef(DBR+str(row['paperID']))))\n",
    "     g.add((URIRef(DBR+str(consistent_hash(row['content']))), DBO.is_assigned_by, URIRef(DBR+coordinator)))\n",
    "     \n",
    "\n",
    "##############################################################\n",
    "\n",
    "# Paper -is_written-> Author\n",
    "# Paper -is_corresponding_author-> Author\n",
    "path='data/wrote_relationships.csv'\n",
    "df=pd.read_csv(path,sep=\",\")\n",
    "for index, row in df.iterrows():\n",
    "    if row['corresponding'] == True:\n",
    "        g.add((URIRef(DBR+str(row['paperID'])), DBO.is_corresponding_author, URIRef(DBR+str(row['authorID']))))\n",
    "    elif row['corresponding'] == False:\n",
    "        g.add((URIRef(DBR+str(row['paperID'])), DBO.is_written, URIRef(DBR+str(row['authorID']))))\n",
    "        \n",
    "# Paper -cites-> Paper\n",
    "path='data/citation_relationships.csv'\n",
    "df=pd.read_csv(path,sep=\",\")\n",
    "for index, row in df.iterrows():\n",
    "    g.add((URIRef(DBR+str(row['citingPaperID'])), DBO.cites, URIRef(DBR+str(row['citedPaperID']))))\n",
    "\n",
    "# Paper -is_about-> Keyword\n",
    "path='data/keyword_relationships.csv'\n",
    "df=pd.read_csv(path,sep=\",\")\n",
    "for index, row in df.iterrows():\n",
    "    g.add((URIRef(DBR+str(row['paperID'])), DBO.is_about, URIRef(DBR+str(row['keywords']).replace(\" \", \"\"))))\n",
    "\n",
    "# EventEdition -held_in_city-> City\n",
    "# EventEdition -held_in_year-> Year\n",
    "path='data/editions.csv'\n",
    "df=pd.read_csv(path,sep=\",\")\n",
    "for index, row in df.iterrows():\n",
    "    g.add((URIRef(DBR+str(row['editionID'])), DBO.held_in_city, URIRef(DBR+str(row['city']))))\n",
    "    g.add((URIRef(DBR+str(row['editionID'])), DBO.held_in_year, URIRef(DBR+str(row['year']))))\n",
    "\n",
    "# JournalVolume -of_year-> Year\n",
    "path='data/volumes.csv'\n",
    "df=pd.read_csv(path,sep=\",\")\n",
    "for index, row in df.iterrows():\n",
    "    g.add((URIRef(DBR+str(row['volumeID']).replace(\" \", \"\")), DBO.of_year, URIRef(DBR+str(row['year']))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2900df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@prefix dbo: <http://dbpedia.org/ontology/> .\n",
      "@prefix dbr: <http://dbpedia.org/resource/> .\n",
      "@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\n",
      "@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
      "\n",
      "dbo:Author a rdfs:Class ;\n",
      "    rdfs:subClassOf dbo:Person .\n",
      "\n",
      "dbo:City a rdfs:Class .\n",
      "\n",
      "dbo:Conference a rdfs:Class .\n",
      "\n",
      "dbo:ConferenceChair a rdfs:Class ;\n",
      "    rdfs:subClassOf dbo:Coordinator .\n",
      "\n",
      "dbo:ConferenceEdition a rdfs:Class ;\n",
      "    rdfs:subClassOf dbo:EventEdition .\n",
      "\n",
      "dbo:Coordinator a rdfs:Class ;\n",
      "    rdfs:subClassOf dbo:Person .\n",
      "\n",
      "dbo:EventEdition a rdfs:Class .\n",
      "\n",
      "dbo:Journal a rdfs:Class .\n",
      "\n",
      "dbo:JournalEditor a rdfs:Class ;\n",
      "    rdfs:subClassOf dbo:Coordinator .\n",
      "\n",
      "dbo:JournalVolume a rdfs:Class .\n",
      "\n",
      "dbo:Keyword a rdfs:Class .\n",
      "\n",
      "dbo:Paper a rdfs:Class .\n",
      "\n",
      "dbo:Person a rdfs:Class .\n",
      "\n",
      "dbo:Review a rdfs:Class .\n",
      "\n",
      "dbo:Reviewer a rdfs:Class ;\n",
      "    rdfs:subClassOf dbo:Author .\n",
      "\n",
      "dbo:Workshop a rdfs:Class .\n",
      "\n",
      "dbo:WorkshopEdition a rdfs:Class ;\n",
      "    rdfs:subClassOf dbo:EventEdition .\n",
      "\n",
      "dbo:Year a rdfs:Class .\n",
      "\n",
      "dbo:cites a rdf:Property ;\n",
      "    rdfs:domain dbo:Paper ;\n",
      "    rdfs:range dbo:Paper .\n",
      "\n",
      "dbo:corresponds_to_paper a rdf:Property ;\n",
      "    rdfs:domain dbo:Review ;\n",
      "    rdfs:range dbo:Paper .\n",
      "\n",
      "dbo:edits a rdf:Property ;\n",
      "    rdfs:domain dbo:JournalEditor ;\n",
      "    rdfs:range dbo:Journal .\n",
      "\n",
      "dbo:held_in_city a rdf:Property ;\n",
      "    rdfs:domain dbo:EventEdition ;\n",
      "    rdfs:range dbo:City .\n",
      "\n",
      "dbo:held_in_year a rdf:Property ;\n",
      "    rdfs:domain dbo:EventEdition ;\n",
      "    rdfs:range dbo:Year .\n",
      "\n",
      "dbo:is_about a rdf:Property ;\n",
      "    rdfs:domain dbo:Paper ;\n",
      "    rdfs:range dbo:Keyword .\n",
      "\n",
      "dbo:is_assigned_by a rdf:Property ;\n",
      "    rdfs:domain dbo:Review ;\n",
      "    rdfs:range dbo:Coordinator .\n",
      "\n",
      "dbo:is_corresponding_author a rdf:Property ;\n",
      "    rdfs:domain dbo:Paper ;\n",
      "    rdfs:range dbo:Author ;\n",
      "    rdfs:subPropertyOf dbo:is_written .\n",
      "\n",
      "dbo:is_edition_of_conf a rdf:Property ;\n",
      "    rdfs:domain dbo:ConferenceEdition ;\n",
      "    rdfs:range dbo:Conference .\n",
      "\n",
      "dbo:is_edition_of_workshop a rdf:Property ;\n",
      "    rdfs:domain dbo:WorkshopEdition ;\n",
      "    rdfs:range dbo:Workshop .\n",
      "\n",
      "dbo:is_volume_of a rdf:Property ;\n",
      "    rdfs:domain dbo:JournalVolume ;\n",
      "    rdfs:range dbo:Journal .\n",
      "\n",
      "dbo:of_year a rdf:Property ;\n",
      "    rdfs:domain dbo:JournalVolume ;\n",
      "    rdfs:range dbo:Year .\n",
      "\n",
      "dbo:organizes_conference a rdf:Property ;\n",
      "    rdfs:domain dbo:ConferenceChair ;\n",
      "    rdfs:range dbo:Conference .\n",
      "\n",
      "dbo:organizes_workshop a rdf:Property ;\n",
      "    rdfs:domain dbo:ConferenceChair ;\n",
      "    rdfs:range dbo:Workshop .\n",
      "\n",
      "dbo:presentedAt a rdf:Property ;\n",
      "    rdfs:domain dbo:Paper ;\n",
      "    rdfs:range dbo:EventEdition .\n",
      "\n",
      "dbo:published_in a rdf:Property ;\n",
      "    rdfs:domain dbo:Paper ;\n",
      "    rdfs:range dbo:JournalVolume .\n",
      "\n",
      "dbo:review_written_by a rdf:Property ;\n",
      "    rdfs:domain dbo:Review ;\n",
      "    rdfs:range dbo:Reviewer .\n",
      "\n",
      "dbr:06214a0cf38875da38586e81539890f7ad8aeb1c dbo:is_about dbr:dataprocessing .\n",
      "\n",
      "dbr:0c7e1338a9c7914a3b9a5bdc42b457b3f272160e dbo:published_in <http://dbpedia.org/resource/ArXiv_vol_abs/1811.00855> .\n",
      "\n",
      "dbr:5c27487c3e0894b65e976a287e6f8c9aa40f089c dbo:published_in dbr:ProceedingsofInternationalConferenceonImageProcessing_vol_1 .\n",
      "\n",
      "dbr:5d1bfeed240709725c78bc72ea40e55410b373dc dbo:published_in <http://dbpedia.org/resource/ArXiv_vol_abs/1509.09292> .\n",
      "\n",
      "dbr:6017e81c5ede6c38b306a3df9738aeb04baa7619 dbo:published_in <http://dbpedia.org/resource/ArXiv_vol_abs/1809.05679> .\n",
      "\n",
      "dbr:6b7d6e6416343b2a122f8416e69059ce919026ef dbo:is_about dbr:NLP .\n",
      "\n",
      "dbr:a0edb93b-1e95-4128-a295-6b1659149cef_edition_2014 dbo:held_in_city dbr:Oslo ;\n",
      "    dbo:held_in_year dbr:2014 .\n",
      "\n",
      "dbr:a0edb93b-1e95-4128-a295-6b1659149cef_edition_2018 dbo:held_in_city dbr:Padova ;\n",
      "    dbo:held_in_year dbr:2018 .\n",
      "\n",
      "dbr:abf805ce186d86e900c704c6920da89e590aa854 dbo:published_in dbr:Bioinformatics_vol_2214 .\n",
      "\n",
      "dbr:b94c7ff9532ab26c3aedbee3988ec4c7a237c173 dbo:cites dbr:04f3c32e51df9f93163cc424b8eb40d82ebf82f1,\n",
      "        dbr:20331628c5cadfa9fa6360e8bdd59b52fde0dcf3,\n",
      "        dbr:4284560b51240cd1d2ee5f97615cc7f910577903,\n",
      "        dbr:4b3dbc36ae4d8171f9a4179001e37299554f1652,\n",
      "        dbr:76f3b19858a14778322efb97dca16b80ddc65879 ;\n",
      "    dbo:is_about dbr:computervision,\n",
      "        dbr:dataquerying .\n",
      "\n",
      "dbr:bdc2e585-4e48-4e36-8af1-6d859763d405_edition_2018 dbo:held_in_city dbr:Bucharest ;\n",
      "    dbo:held_in_year dbr:2018 .\n",
      "\n",
      "dbr:d9720b90-d60b-48bc-9df8-87a30b9a60dd_edition_2001 dbo:held_in_city dbr:Paris ;\n",
      "    dbo:held_in_year dbr:2001 .\n",
      "\n",
      "dbr:d9720b90-d60b-48bc-9df8-87a30b9a60dd_edition_2017 dbo:held_in_city dbr:Berlin ;\n",
      "    dbo:held_in_year dbr:2017 .\n",
      "\n",
      "dbr:fff114cbba4f3ba900f33da574283e3de7f26c83 dbo:is_about dbr:NLP .\n",
      "\n",
      "dbo:is_written a rdf:Property ;\n",
      "    rdfs:domain dbo:Paper ;\n",
      "    rdfs:range dbo:Author .\n",
      "\n",
      "<http://dbpedia.org/resource/ArXiv_vol_abs/1509.09292> dbo:is_volume_of dbr:ArXiv ;\n",
      "    dbo:of_year dbr:2015 .\n",
      "\n",
      "<http://dbpedia.org/resource/ArXiv_vol_abs/1809.05679> dbo:is_volume_of dbr:ArXiv ;\n",
      "    dbo:of_year dbr:2018 .\n",
      "\n",
      "<http://dbpedia.org/resource/ArXiv_vol_abs/1811.00855> dbo:is_volume_of dbr:ArXiv ;\n",
      "    dbo:of_year dbr:2018 .\n",
      "\n",
      "dbr:Bioinformatics_vol_2214 dbo:is_volume_of dbr:Bioinformatics ;\n",
      "    dbo:of_year dbr:2006 .\n",
      "\n",
      "dbr:ProceedingsofInternationalConferenceonImageProcessing_vol_1 dbo:is_volume_of dbr:ProceedingsofInternationalConferenceonImageProcessing ;\n",
      "    dbo:of_year dbr:1997 .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g.serialize(\"output_files/abox.ttl\", format=\"turtle\")\n",
    "print(g.serialize(format=\"turtle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0db1828f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total triples before inference: 129275\n",
      "Total triples after inference: 240270\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total triples before inference: {len(g)}\")\n",
    "# Apply RDFS reasoning\n",
    "DeductiveClosure(RDFS_Semantics).expand(g)\n",
    "\n",
    "print(f\"Total triples after inference: {len(g)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fa623b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import re\n",
    "\n",
    "def extract_nodes(s):\n",
    "     # keep the string after the last hashtag or frontslash\n",
    "    match = re.search(r'[^/#]+$', s)\n",
    "    return str(match.group(0)) if match else None\n",
    "\n",
    "def extract_edge(s):\n",
    "    # keep the string after the last hashtag or frontslash\n",
    "    match = re.search(r'[^/#]+$', s)\n",
    "    label = str(match.group(0)) \n",
    "    if label == 'type':\n",
    "        label = 'rdf:type'\n",
    "    elif label in ['range', 'domain', 'subClassOf', 'subPropertyOf']:\n",
    "        label = 'rdfs:' + label\n",
    "    return label if match else None\n",
    "    \n",
    "\n",
    "G = nx.DiGraph()\n",
    "\n",
    "for s, p, o in g:\n",
    "    G.add_edge(extract_nodes(s),\n",
    "               extract_nodes(o),\n",
    "               label=extract_edge(p))\n",
    "\n",
    "nx.write_graphml(G, \"output_files/inference.graphml\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
